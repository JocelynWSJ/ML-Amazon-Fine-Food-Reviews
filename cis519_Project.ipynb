{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " cis519_Project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JocelynWSJ/ML-Amazon-Fine-Food-Reviews/blob/main/cis519_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtfiePPZxPXY"
      },
      "source": [
        "#Part0 - Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgHo3yjexQvP",
        "outputId": "a522a737-c6be-45f9-e89c-c5cb0fd7334b"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/Shareddrives/cis519_project"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/Shareddrives/cis519_project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3GWsy4oxHvB",
        "outputId": "37a9377f-d25d-4a69-e042-3324ad7c4fab"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "!pip3 install pandasql\n",
        "import pandasql as ps\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import re\n",
        "from sklearn import datasets, linear_model\n",
        "from sklearn.metrics import mean_squared_error, r2_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pandasql\n",
            "  Downloading https://files.pythonhosted.org/packages/6b/c4/ee4096ffa2eeeca0c749b26f0371bd26aa5c8b611c43de99a4f86d3de0a7/pandasql-0.7.3.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pandasql) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pandasql) (1.1.5)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from pandasql) (1.4.7)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pandasql) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->pandasql) (2.8.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->pandasql) (1.0.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->pandasql) (3.10.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->pandasql) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy->pandasql) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->sqlalchemy->pandasql) (3.4.1)\n",
            "Building wheels for collected packages: pandasql\n",
            "  Building wheel for pandasql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pandasql: filename=pandasql-0.7.3-cp37-none-any.whl size=26820 sha256=0a87a0c2e161ee001c0b5f7766853903f2786b76c03749c9842a8fe782537bff\n",
            "  Stored in directory: /root/.cache/pip/wheels/53/6c/18/b87a2e5fa8a82e9c026311de56210b8d1c01846e18a9607fc9\n",
            "Successfully built pandasql\n",
            "Installing collected packages: pandasql\n",
            "Successfully installed pandasql-0.7.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_8Q6x78JiOW"
      },
      "source": [
        "#Part1-Operations on 'Summary' column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPdUbjcaReZR"
      },
      "source": [
        "## 1.1 Logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "at3SbWkcQyS3",
        "outputId": "f9354d54-84c9-4177-ed26-e76111d010f0"
      },
      "source": [
        "# Read in the csv file\n",
        "df = pd.read_csv('Reviews.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ...                                               Text\n",
              "0   1  ...  I have bought several of the Vitality canned d...\n",
              "1   2  ...  Product arrived labeled as Jumbo Salted Peanut...\n",
              "2   3  ...  This is a confection that has been around a fe...\n",
              "3   4  ...  If you are looking for the secret ingredient i...\n",
              "4   5  ...  Great taffy at a great price.  There was a wid...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "ZhPlJmkrRBRF",
        "outputId": "33cec4fd-7d3c-47e3-d41a-2e30e3a80f84"
      },
      "source": [
        "# show the summary column\n",
        "df_summary = df[['Summary']]\n",
        "df_summary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not as Advertised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cough Medicine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Great taffy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568449</th>\n",
              "      <td>Will not do without</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568450</th>\n",
              "      <td>disappointed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568451</th>\n",
              "      <td>Perfect for our maltipoo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568452</th>\n",
              "      <td>Favorite Training and reward treat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568453</th>\n",
              "      <td>Great Honey</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>568454 rows Ã— 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                   Summary\n",
              "0                    Good Quality Dog Food\n",
              "1                        Not as Advertised\n",
              "2                    \"Delight\" says it all\n",
              "3                           Cough Medicine\n",
              "4                              Great taffy\n",
              "...                                    ...\n",
              "568449                 Will not do without\n",
              "568450                        disappointed\n",
              "568451            Perfect for our maltipoo\n",
              "568452  Favorite Training and reward treat\n",
              "568453                         Great Honey\n",
              "\n",
              "[568454 rows x 1 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybKipIu6RH0h"
      },
      "source": [
        "### Predicting Score with Raw Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfRaE1xoRbK8",
        "outputId": "c240472b-64c3-4741-9b4e-ce20875c1cd4"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df.dropna(inplace=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Summary'], df['Score'], random_state = 42)\n",
        "print('X_train first entry:', X_train[0])\n",
        "print('X_train shape:', X_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train first entry: Good Quality Dog Food\n",
            "X_train shape: (426308,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LpjdxHJRh9q",
        "outputId": "5a11d076-9563-46ed-8939-e7ba379965b8"
      },
      "source": [
        "# Using CountVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "vect = CountVectorizer().fit(X_train)\n",
        "clf_SGD = SGDClassifier(loss='log', max_iter=10000, random_state=42)\n",
        "X_train_vectorized = vect.transform(X_train)\n",
        "clf_SGD.fit(X_train_vectorized, y_train)\n",
        "train_pred = clf_SGD.predict(X_train_vectorized)\n",
        "test_pred = clf_SGD.predict(vect.transform(X_test))\n",
        "train_acc = accuracy_score(train_pred, y_train)\n",
        "test_acc = accuracy_score(test_pred, y_test)\n",
        "f1 = f1_score(test_pred, y_test, average='weighted')\n",
        "\n",
        "print('train accuracy:', round(train_acc, 3))\n",
        "print('test accuracy:', round(test_acc, 3))\n",
        "print('f1 score:', round(f1,3))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train accuracy: 0.701\n",
            "test accuracy: 0.701\n",
            "f1 score: 0.768\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tNud7X4LSb2_"
      },
      "source": [
        "### Predicting Score with Created Word Dictionary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjruAV0nxoUY"
      },
      "source": [
        "import string\n",
        "import tensorflow_datasets as tfds\n",
        "def labeler(example, index):\n",
        "  return example, tf.cast(index, tf.int64)  \n",
        "\n",
        "def delete_punc(x):\n",
        "  punctuation_string = string.punctuation\n",
        "  for s in punctuation_string:\n",
        "    x = x.replace(s,'')\n",
        "  return x\n",
        "\n",
        "def prepare(x):\n",
        "  x = str(x)\n",
        "  x = x.split()\n",
        "  x = [s.strip() for s in x]\n",
        "  x = [s.lower() for s in x]\n",
        "  x = map(lambda te: delete_punc(te),x)\n",
        "  return list(x)\n",
        "\n",
        "df_summary = df_summary[:100000]\n",
        "save = []\n",
        "\n",
        "a = df_summary['Summary'].apply(prepare)\n",
        "for i in range(len(a)):\n",
        "    save.extend(a[i])\n",
        "save = list(set(save))\n",
        "\n",
        "for item in save: \n",
        "  if len(item)<= 1:\n",
        "    save.remove(item)\n",
        "#Create two dictionaries \n",
        "# index: word\n",
        "word_index = {k:v for k,v in enumerate(save)}\n",
        "# word: index\n",
        "number_index = dict([(value, key) for (key, value) in word_index.items()])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhyeAlAz2nCB"
      },
      "source": [
        "#Convert the word into numbers\n",
        "#input total_save\n",
        "total_save = []\n",
        "df_summary = df_summary[:100000]\n",
        "temdf = df_summary['Summary'].apply(prepare)\n",
        "temdf\n",
        "for i in (range(len(temdf))):\n",
        "  # print(i)\n",
        "  index_save = []\n",
        "  for item in temdf[i]:\n",
        "    if len(item)>1:\n",
        "      # print(number_index[item])\n",
        "      index_save.append(number_index[item])\n",
        "  total_save.append(index_save)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ8-HABaTuBy"
      },
      "source": [
        "# input\n",
        "train_data = total_save\n",
        "# output\n",
        "y_label = np.array(df['Score'])\n",
        "y_label = y_label[:100000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2vaTBE3Tyuk"
      },
      "source": [
        "from tensorflow import keras\n",
        "\n",
        "train_data = total_save[:90000]\n",
        "test_data = total_save[90000:]\n",
        "\n",
        "train_label = y_label[:90000]\n",
        "test_label = y_label[90000:]\n",
        "\n",
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data,padding='post',maxlen = 32)\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data,padding='post',maxlen=32)\n",
        "\n",
        "X_train = train_data\n",
        "y_train = train_label\n",
        "X_test = test_data\n",
        "y_test = test_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gYOuomyRUAfO",
        "outputId": "36d62435-60fb-4780-9c9f-71f1f002fdbc"
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "clf_SGD = SGDClassifier(loss='log', max_iter=10000, random_state=42)\n",
        "clf_SGD.fit(X_train, y_train)\n",
        "train_pred = clf_SGD.predict(X_train)\n",
        "test_pred = clf_SGD.predict(X_test)\n",
        "train_acc = accuracy_score(train_pred, y_train)\n",
        "test_acc = accuracy_score(test_pred, y_test)\n",
        "f1 = f1_score(test_pred, y_test, average='weighted')\n",
        "\n",
        "print('train accuracy:', round(train_acc, 3))\n",
        "print('test accuracy:', round(test_acc, 3))\n",
        "print('f1 score:', round(f1,3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train accuracy: 0.603\n",
            "test accuracy: 0.618\n",
            "f1 score: 0.74\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-w3EXNCiUTP4"
      },
      "source": [
        "### Predicting Positivity with Clean Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "nAD6wIurU9r8",
        "outputId": "01eaf80c-386e-4efc-d0d9-c8b86e262031"
      },
      "source": [
        "# create a column(Positivity) based on the score \n",
        "df.dropna(inplace=True)\n",
        "df[df['Score'] != 3]\n",
        "df['Positivity'] = np.where(df['Score'] > 3, 1, 0)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "      <th>Positivity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ... Positivity\n",
              "0   1  ...          1\n",
              "1   2  ...          0\n",
              "2   3  ...          1\n",
              "3   4  ...          0\n",
              "4   5  ...          1\n",
              "\n",
              "[5 rows x 11 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aq1-HSPpWm9o"
      },
      "source": [
        "def utils_preprocess_text(text, flg_stemm=False, flg_lemm=True, lst_stopwords=None):\n",
        "  ## clean (convert to lowercase and remove punctuations and  \n",
        "  ## characters and then strip)\n",
        "  text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
        "          \n",
        "  ## Tokenize (convert from string to list)\n",
        "  lst_text = text.split()    ## remove Stopwords\n",
        "  if lst_stopwords is not None:\n",
        "      lst_text = [word for word in lst_text if word not in\n",
        "                  lst_stopwords]\n",
        "  ## Stemming (remove -ing, -ly, ...)\n",
        "  if flg_stemm == True:\n",
        "      ps = nltk.stem.porter.PorterStemmer()\n",
        "      lst_text = [ps.stem(word) for word in lst_text]\n",
        "              \n",
        "  ## Lemmatisation (convert the word into root word)\n",
        "  if flg_lemm == True:\n",
        "      lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "      lst_text = [lem.lemmatize(word) for word in lst_text]\n",
        "          \n",
        "  ## back to string from list\n",
        "  text = \" \".join(lst_text)\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyLoPrbuWnza",
        "outputId": "9cc64d90-f72b-4028-98dd-79ed98920f1a"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "lst_stopwords = stopwords.words(\"english\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "sI0CXdF3Wrux",
        "outputId": "49680ef4-444a-4dd2-9121-23ecc24c093c"
      },
      "source": [
        "import re\n",
        "df[\"Summary_clean\"] = df[\"Summary\"].apply(lambda x:\n",
        "utils_preprocess_text(x, flg_stemm=False, flg_lemm=True,\n",
        "lst_stopwords=lst_stopwords))\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "      <th>Positivity</th>\n",
              "      <th>Summary_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "      <td>1</td>\n",
              "      <td>good quality dog food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "      <td>0</td>\n",
              "      <td>advertised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "      <td>1</td>\n",
              "      <td>delight say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "      <td>0</td>\n",
              "      <td>cough medicine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "      <td>1</td>\n",
              "      <td>great taffy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id   ProductId  ... Positivity          Summary_clean\n",
              "0   1  B001E4KFG0  ...          1  good quality dog food\n",
              "1   2  B00813GRG4  ...          0             advertised\n",
              "2   3  B000LQOCH0  ...          1            delight say\n",
              "3   4  B000UA0QIQ  ...          0         cough medicine\n",
              "4   5  B006K2ZZ7K  ...          1            great taffy\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eocovLWcW4GX"
      },
      "source": [
        "from sklearn import feature_extraction, model_selection\n",
        "data_train,data_test = model_selection.train_test_split(df,test_size = 0.3)\n",
        "\n",
        "X_train = data_train['Summary_clean']\n",
        "X_test = data_test['Summary_clean']\n",
        "y_train = data_train['Positivity']\n",
        "y_test = data_test['Positivity']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kP55o-xVyGo",
        "outputId": "c84bfd86-63e8-4966-9504-35e32ea61a40"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "vect = CountVectorizer().fit(X_train)\n",
        "\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "clf_SGD = SGDClassifier(loss='log', max_iter=10000, random_state=42)\n",
        "X_train_vectorized = vect.transform(X_train)\n",
        "clf_SGD.fit(X_train_vectorized, y_train)\n",
        "train_pred = clf_SGD.predict(X_train_vectorized)\n",
        "test_pred = clf_SGD.predict(vect.transform(X_test))\n",
        "train_acc = accuracy_score(train_pred, y_train)\n",
        "test_acc = accuracy_score(test_pred, y_test)\n",
        "f1 = f1_score(test_pred, y_test, average='weighted')\n",
        "\n",
        "print('train accuracy:', round(train_acc, 3))\n",
        "print('test accuracy:', round(test_acc, 3))\n",
        "print('f1 score:', round(f1,3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train accuracy: 0.856\n",
            "test accuracy: 0.853\n",
            "f1 score: 0.872\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RP27YjCYujW"
      },
      "source": [
        "## 1.2 - Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poWghyZd5o_Q"
      },
      "source": [
        "### Predict score with Summary_clean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdWofqHE5Y_u",
        "outputId": "c38c781e-fe35-4555-ea78-903d272a092b"
      },
      "source": [
        "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing## for explainer\n",
        "\n",
        "vectorizer = feature_extraction.text.CountVectorizer(max_features=10000, ngram_range=(1,2))\n",
        "X = df['Summary_clean']\n",
        "#X = df['text_clean']\n",
        "vectorizer.fit(X)\n",
        "X_matrix = vectorizer.transform(X)\n",
        "# dic_vocabulary = vectorizer.vocabulary_\n",
        "X_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(568411, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WojYgDj258Z-",
        "outputId": "e154ff36-26f2-4ab9-bdf7-5716f26fc749"
      },
      "source": [
        "# Split the data into training/testing sets\n",
        "X_train = X_matrix[:-170000]\n",
        "X_test = X_matrix[-170000:]\n",
        "\n",
        "# Split the targets into training/testing sets\n",
        "y_train = df['Score'][:-170000]\n",
        "y_test = df['Score'][-170000:]\n",
        "\n",
        "print('df shape:', df.shape)\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('X_test shape:', X_test.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_test shape:', y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df shape: (568411, 12)\n",
            "X_train shape: (398411, 10000)\n",
            "X_test shape: (170000, 10000)\n",
            "y_train shape: (398411,)\n",
            "y_test shape: (170000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MC6ES5NY6Isi",
        "outputId": "75baa377-7a33-4b2c-9823-3b7690a5cd5a"
      },
      "source": [
        "# Create linear regression object\n",
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di2CMuRm6MvR",
        "outputId": "d3b524b7-6cb9-4169-8a7c-774cc7bbc9fe"
      },
      "source": [
        "y_pred = regr.predict(X_test)\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5.4317579  3.98548067 4.84396331 ... 4.7058944  5.41802951 4.84908135]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zu-E7DHJ6Op_",
        "outputId": "091f45d9-b3d6-47fb-a6cf-1f4a976992e0"
      },
      "source": [
        "from sklearn.metrics import mean_squared_error,accuracy_score\n",
        "y_test = np.array(y_test).astype(float)\n",
        "y_pred = np.array(y_pred).astype(float)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"MSE: \", mse)\n",
        "\n",
        "from sklearn import metrics\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"r2: \", r2)\n",
        "\n",
        "y_test = list(y_test)\n",
        "y_pred = list(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE:  0.8956631962415149\n",
            "r2:  0.47134965377201943\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nimEQzxY8CJb"
      },
      "source": [
        "### Predict score with new stop word list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7sIlP5zx8Xam",
        "outputId": "ec1ed630-dacc-4d13-eb49-07a8bd969640"
      },
      "source": [
        "stopwords_new = stopwords.words(\"english\")\n",
        "\n",
        "remove_list = ['ain','aren',\"aren't\",'couldn',\"couldn't\",'didn',\"didn't\",'doesn',\"doesn't\",'hadn',\"hadn't\",'hasn',\"hasn't\",'haven',\"haven't\",\n",
        "               'isn',\"isn't\",'ma','mightn',\"mightn't\",'mustn',\"mustn't\",'needn',\"needn't\",'shan',\"shan't\",'shouldn',\"shouldn't\",'wasn',\"wasn't\",\n",
        "               'weren',\"weren't\",'won',\"won't\",'wouldn',\"wouldn't\",'against','no','nor','not','don', \"don't\",'t','s','y','o','d','m']\n",
        "\n",
        "for delItem in remove_list:\n",
        "  stopwords_new.remove(delItem)\n",
        "stopwords_new"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'll',\n",
              " 're',\n",
              " 've']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "nA5EdyMr8nsF",
        "outputId": "0a542141-cee7-4dec-c0ef-f3e6e2b58234"
      },
      "source": [
        "df[\"Summary_clean_new\"] = df[\"Summary\"].apply(lambda x: utils_preprocess_text(x, flg_stemm=False, flg_lemm=True, lst_stopwords=stopwords_new))\n",
        "df_clean = df[[\"Summary\",\"Summary_clean\",\"Summary_clean_new\"]]\n",
        "df_clean.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Summary</th>\n",
              "      <th>Summary_clean</th>\n",
              "      <th>Summary_clean_new</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>good quality dog food</td>\n",
              "      <td>good quality dog food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>advertised</td>\n",
              "      <td>not advertised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>delight say</td>\n",
              "      <td>delight say</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>cough medicine</td>\n",
              "      <td>cough medicine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Great taffy</td>\n",
              "      <td>great taffy</td>\n",
              "      <td>great taffy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Summary          Summary_clean      Summary_clean_new\n",
              "0  Good Quality Dog Food  good quality dog food  good quality dog food\n",
              "1      Not as Advertised             advertised         not advertised\n",
              "2  \"Delight\" says it all            delight say            delight say\n",
              "3         Cough Medicine         cough medicine         cough medicine\n",
              "4            Great taffy            great taffy            great taffy"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dr3dbGUm88_D",
        "outputId": "dc3d2864-b14f-4e94-d43c-6a2120f36ed1"
      },
      "source": [
        "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing## for explainer\n",
        "\n",
        "vectorizer = feature_extraction.text.CountVectorizer(max_features=10000, ngram_range=(1,2))\n",
        "X = df['Summary_clean_new']\n",
        "#X = df['text_clean']\n",
        "vectorizer.fit(X)\n",
        "X_matrix = vectorizer.transform(X)\n",
        "# dic_vocabulary = vectorizer.vocabulary_\n",
        "X_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(568411, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwTGMAg79FNv",
        "outputId": "7dc3abbc-38d3-4970-966c-359adc7927b2"
      },
      "source": [
        "# Split the data into training/testing sets\n",
        "X_train = X_matrix[:-170000]\n",
        "X_test = X_matrix[-170000:]\n",
        "\n",
        "# Split the targets into training/testing sets\n",
        "y_train = df['Score'][:-170000]\n",
        "y_test = df['Score'][-170000:]\n",
        "\n",
        "print('df shape:', df.shape)\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('X_test shape:', X_test.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_test shape:', y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df shape: (568411, 13)\n",
            "X_train shape: (398411, 10000)\n",
            "X_test shape: (170000, 10000)\n",
            "y_train shape: (398411,)\n",
            "y_test shape: (170000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8d7P3hk9Irs",
        "outputId": "57b4fd6d-2c64-47f6-df55-a8731e20f099"
      },
      "source": [
        "# Create linear regression object\n",
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X4olGD3M9RBH",
        "outputId": "3c074879-2940-4c8f-bc20-82a004c6fc6b"
      },
      "source": [
        "y_pred = regr.predict(X_test)\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[5.39851157 3.97827295 4.85442688 ... 4.73929285 5.50544525 4.8897335 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVyUW6df9Up_",
        "outputId": "ad523929-38c8-4d1a-fee2-dab05ee75f89"
      },
      "source": [
        "y_test = np.array(y_test).astype(float)\n",
        "y_pred = np.array(y_pred).astype(float)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"MSE: \", mse)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"r2: \", r2)\n",
        "\n",
        "y_test = list(y_test)\n",
        "y_pred = list(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE:  0.7806817634657832\n",
            "r2:  0.5392155374007683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5SFkBuk9qnO"
      },
      "source": [
        "### Predict positivity"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mAeo1PVD91K7",
        "outputId": "1445dadf-0c4b-45f3-c72d-6011e0b43404"
      },
      "source": [
        "# Split the data into training/testing sets\n",
        "X_train = X_matrix[:-170000]\n",
        "X_test = X_matrix[-170000:]\n",
        "\n",
        "# Split the targets into training/testing sets\n",
        "y_train = df['Positivity'][:-170000]\n",
        "y_test = df['Positivity'][-170000:]\n",
        "\n",
        "print('df shape:', df.shape)\n",
        "print('X_train shape:', X_train.shape)\n",
        "print('X_test shape:', X_test.shape)\n",
        "print('y_train shape:', y_train.shape)\n",
        "print('y_test shape:', y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "df shape: (568411, 13)\n",
            "X_train shape: (398411, 10000)\n",
            "X_test shape: (170000, 10000)\n",
            "y_train shape: (398411,)\n",
            "y_test shape: (170000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vLlahViy96Nn",
        "outputId": "4499b80c-397a-471a-d107-54982d94ab90"
      },
      "source": [
        "# Create linear regression object\n",
        "regr = linear_model.LinearRegression()\n",
        "\n",
        "# Train the model using the training sets\n",
        "regr.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yO553xvs9-Od",
        "outputId": "ec648dbd-c1d4-4d02-8662-c4df83ec899a"
      },
      "source": [
        "y_pred = regr.predict(X_test)\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.15042359 0.70466835 0.99024938 ... 0.93669791 1.16678242 1.00430004]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pwUecmkU-AT_",
        "outputId": "8a9b46d5-b42d-4df0-e3f1-79e9db364dac"
      },
      "source": [
        "y_test = np.array(y_test).astype(float)\n",
        "y_pred = np.array(y_pred).astype(float)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(\"MSE: \", mse)\n",
        "\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"r2: \", r2)\n",
        "\n",
        "y_pred = np.round(y_pred)\n",
        "accuracy_score = accuracy_score(y_test, y_pred)\n",
        "print(\"accuracy_score: \", accuracy_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE:  0.0833565991062954\n",
            "r2:  0.5077482014439189\n",
            "accuracy_score:  0.8942529411764706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q39TYXdaXxND"
      },
      "source": [
        "# Part2 - Operations on the comment column"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tgg6B5zWSyZK"
      },
      "source": [
        "## 2.1 Text prepocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy9YfH9qS3V9",
        "outputId": "d910d0c5-0566-451a-a318-6d9802e597ae"
      },
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn import feature_extraction, model_selection, naive_bayes, pipeline, manifold, preprocessing\n",
        "!pip install lime\n",
        "from lime import lime_text\n",
        "import gensim\n",
        "import gensim.downloader as gensim_api\n",
        "from tensorflow.keras import models, layers, preprocessing as kprocessing\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/86/91a13127d83d793ecb50eb75e716f76e6eda809b6803c5a4ff462339789e/lime-0.2.0.1.tar.gz (275kB)\n",
            "\r\u001b[K     |â–ˆâ–                              | 10kB 8.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–                             | 20kB 10.5MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–‹                            | 30kB 8.5MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–Š                           | 40kB 5.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 51kB 7.1MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                        | 61kB 7.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                       | 71kB 8.2MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                      | 81kB 9.1MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                     | 92kB 8.8MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                    | 102kB 7.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                   | 112kB 7.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                 | 122kB 7.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                | 133kB 7.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 143kB 7.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰              | 153kB 7.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ             | 163kB 7.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–           | 174kB 7.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–          | 184kB 7.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹         | 194kB 7.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š        | 204kB 7.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ       | 215kB 7.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–     | 225kB 7.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 235kB 7.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 245kB 7.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 256kB 7.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 266kB 7.9MB/s eta 0:00:01\r\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 276kB 7.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from lime) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lime) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lime) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from lime) (4.41.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from lime) (0.22.2.post1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/dist-packages (from lime) (0.16.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (2.8.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (0.10.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (1.0.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.4.1)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.5.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->lime) (1.15.0)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.12->lime) (4.4.2)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-cp37-none-any.whl size=283846 sha256=7f3eed38815775f35360891ac844eb3334efc64055f5802dec886a6f7bb31b53\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/4f/a5/0bc765457bd41378bf3ce8d17d7495369d6e7ca3b712c60c89\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "b1TW89uHSuhg",
        "outputId": "b338526f-b087-4068-96e9-40c08d1e9ae5"
      },
      "source": [
        "df = pd.read_csv('Reviews.csv')\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>ProductId</th>\n",
              "      <th>UserId</th>\n",
              "      <th>ProfileName</th>\n",
              "      <th>HelpfulnessNumerator</th>\n",
              "      <th>HelpfulnessDenominator</th>\n",
              "      <th>Score</th>\n",
              "      <th>Time</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>B001E4KFG0</td>\n",
              "      <td>A3SGXH7AUHU8GW</td>\n",
              "      <td>delmartian</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1303862400</td>\n",
              "      <td>Good Quality Dog Food</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>B00813GRG4</td>\n",
              "      <td>A1D87F6ZCVE5NK</td>\n",
              "      <td>dll pa</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1346976000</td>\n",
              "      <td>Not as Advertised</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>B000LQOCH0</td>\n",
              "      <td>ABXLMWJIXXAIN</td>\n",
              "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1219017600</td>\n",
              "      <td>\"Delight\" says it all</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>B000UA0QIQ</td>\n",
              "      <td>A395BORC6FGVXV</td>\n",
              "      <td>Karl</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>1307923200</td>\n",
              "      <td>Cough Medicine</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>B006K2ZZ7K</td>\n",
              "      <td>A1UQRSCLF8GW1T</td>\n",
              "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1350777600</td>\n",
              "      <td>Great taffy</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Id  ...                                               Text\n",
              "0   1  ...  I have bought several of the Vitality canned d...\n",
              "1   2  ...  Product arrived labeled as Jumbo Salted Peanut...\n",
              "2   3  ...  This is a confection that has been around a fe...\n",
              "3   4  ...  If you are looking for the secret ingredient i...\n",
              "4   5  ...  Great taffy at a great price.  There was a wid...\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "_gJ5411IUVoF",
        "outputId": "defe7e50-5c0a-4baf-faff-320e22e49a60"
      },
      "source": [
        "df_target = df[['Id','Score','Text']]\n",
        "df_target"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Score</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>I have bought several of the Vitality canned d...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>This is a confection that has been around a fe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>If you are looking for the secret ingredient i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>Great taffy at a great price.  There was a wid...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568449</th>\n",
              "      <td>568450</td>\n",
              "      <td>5</td>\n",
              "      <td>Great for sesame chicken..this is a good if no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568450</th>\n",
              "      <td>568451</td>\n",
              "      <td>2</td>\n",
              "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568451</th>\n",
              "      <td>568452</td>\n",
              "      <td>5</td>\n",
              "      <td>These stars are small, so you can give 10-15 o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568452</th>\n",
              "      <td>568453</td>\n",
              "      <td>5</td>\n",
              "      <td>These are the BEST treats for training and rew...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568453</th>\n",
              "      <td>568454</td>\n",
              "      <td>5</td>\n",
              "      <td>I am very satisfied ,product is as advertised,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>568454 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Id  Score                                               Text\n",
              "0            1      5  I have bought several of the Vitality canned d...\n",
              "1            2      1  Product arrived labeled as Jumbo Salted Peanut...\n",
              "2            3      4  This is a confection that has been around a fe...\n",
              "3            4      2  If you are looking for the secret ingredient i...\n",
              "4            5      5  Great taffy at a great price.  There was a wid...\n",
              "...        ...    ...                                                ...\n",
              "568449  568450      5  Great for sesame chicken..this is a good if no...\n",
              "568450  568451      2  I'm disappointed with the flavor. The chocolat...\n",
              "568451  568452      5  These stars are small, so you can give 10-15 o...\n",
              "568452  568453      5  These are the BEST treats for training and rew...\n",
              "568453  568454      5  I am very satisfied ,product is as advertised,...\n",
              "\n",
              "[568454 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HPFUDRnMTLfh"
      },
      "source": [
        "###Check the Score Distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "PDJjpGmMbzst",
        "outputId": "15386c6e-297d-42f9-f9e9-0b1293a25888"
      },
      "source": [
        "\n",
        "fig, ax = plt.subplots()\n",
        "fig.suptitle(\"Score Distribution\")\n",
        "df_target['Score'].reset_index().groupby('Score').count().sort_values(by= \n",
        "\"index\").plot(kind=\"barh\", legend=False,ax=ax).grid(axis='x')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "M7u5ZFKolpTb",
        "outputId": "c3ad7a79-18f3-4e72-c365-b7bec150fe15"
      },
      "source": [
        "df_target['Score'].reset_index().groupby('Score').count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Score</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>52268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>29769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>42640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>80655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>363122</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        index\n",
              "Score        \n",
              "1       52268\n",
              "2       29769\n",
              "3       42640\n",
              "4       80655\n",
              "5      363122"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "id": "kDhbF8vfmOGr",
        "outputId": "a6a6973a-6979-42f5-8ea1-c57094ba70a5"
      },
      "source": [
        "#Make the distribution balanced\n",
        "df_score5 = df_target[df_target['Score']==5]\n",
        "df_score5 = df_score5.sample(frac = 0.08,random_state=42)\n",
        "df_score4 = df_target[df_target['Score']==4]\n",
        "df_score4 = df_score4.sample(frac = 0.3,random_state=42)\n",
        "df_score3 = df_target[df_target['Score']==3]\n",
        "df_score3 = df_score3.sample(frac = 0.5,random_state=42)\n",
        "df_score2 = df_target[df_target['Score']==2]\n",
        "df_score2 = df_score2.sample(frac = 0.9,random_state=42)\n",
        "df_score1 = df_target[df_target['Score']==1]\n",
        "df_score1 = df_score1.sample(frac = 0.55,random_state=42)\n",
        "\n",
        "df_balanced = pd.concat([df_score5,df_score4,df_score3,df_score2,df_score1],axis=0)\n",
        "df_balanced = df_balanced.sample(frac=1,random_state=42)\n",
        "df_balanced\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Score</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>465223</th>\n",
              "      <td>465224</td>\n",
              "      <td>1</td>\n",
              "      <td>I love Amazon...but this product showed up wit...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4698</th>\n",
              "      <td>4699</td>\n",
              "      <td>3</td>\n",
              "      <td>The set is bigger than I thought it would be. ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143999</th>\n",
              "      <td>144000</td>\n",
              "      <td>4</td>\n",
              "      <td>Clorets has been my favorite gum since the 80'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298975</th>\n",
              "      <td>298976</td>\n",
              "      <td>4</td>\n",
              "      <td>Slightly richer chocolate taste over the milk ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361440</th>\n",
              "      <td>361441</td>\n",
              "      <td>1</td>\n",
              "      <td>As a connoissuer of a wide variety of fine loo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370885</th>\n",
              "      <td>370886</td>\n",
              "      <td>1</td>\n",
              "      <td>Item tasted plain and was crumbly. Did not tas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245916</th>\n",
              "      <td>245917</td>\n",
              "      <td>1</td>\n",
              "      <td>First of all, the picture that Amazon has with...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18990</th>\n",
              "      <td>18991</td>\n",
              "      <td>5</td>\n",
              "      <td>Shipment arrived on time and in good condition...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105286</th>\n",
              "      <td>105287</td>\n",
              "      <td>5</td>\n",
              "      <td>I'm a big fan of the Blue Diamond brand almond...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436911</th>\n",
              "      <td>436912</td>\n",
              "      <td>1</td>\n",
              "      <td>I like to give my puppy healthy , nutritious f...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>130105 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Id  Score                                               Text\n",
              "465223  465224      1  I love Amazon...but this product showed up wit...\n",
              "4698      4699      3  The set is bigger than I thought it would be. ...\n",
              "143999  144000      4  Clorets has been my favorite gum since the 80'...\n",
              "298975  298976      4  Slightly richer chocolate taste over the milk ...\n",
              "361440  361441      1  As a connoissuer of a wide variety of fine loo...\n",
              "...        ...    ...                                                ...\n",
              "370885  370886      1  Item tasted plain and was crumbly. Did not tas...\n",
              "245916  245917      1  First of all, the picture that Amazon has with...\n",
              "18990    18991      5  Shipment arrived on time and in good condition...\n",
              "105286  105287      5  I'm a big fan of the Blue Diamond brand almond...\n",
              "436911  436912      1  I like to give my puppy healthy , nutritious f...\n",
              "\n",
              "[130105 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "id": "fxwV7437mOIA",
        "outputId": "bfb9a7af-dad0-4a4b-8a21-d4c0e07f950b"
      },
      "source": [
        "#Check the Score Distribution\n",
        "fig, ax = plt.subplots()\n",
        "fig.suptitle(\"Score Distribution\", fontsize=12)\n",
        "df_balanced['Score'].reset_index().groupby('Score').count().sort_values(by= \n",
        "       \"index\").plot(kind=\"barh\", legend=False, \n",
        "        ax=ax).grid(axis='x')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPErFM6PppZj"
      },
      "source": [
        "df_target = df_balanced"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNyN5nAaUviB"
      },
      "source": [
        "### Clean Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4EgNsynU3qq"
      },
      "source": [
        "def utils_preprocess_text(text, flg_lemm=True, lst_stopwords=None):\n",
        "  '''\n",
        "  Tokenize\n",
        "  Stemming\n",
        "  Lemmation\n",
        "  '''\n",
        "  text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
        "          \n",
        "  ## Tokenize (convert from string to list)\n",
        "  lst_text = text.split()    ## remove Stopwords\n",
        "  if lst_stopwords is not None:\n",
        "    lst_text = [word for word in lst_text if word not in\n",
        "                lst_stopwords]\n",
        "              \n",
        "  ## convert the word into root word\n",
        "  if flg_lemm == True:\n",
        "    lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "    lst_text = [lem.lemmatize(word) for word in lst_text]\n",
        "        \n",
        "  ## back to string from list\n",
        "  text = \" \".join(lst_text)\n",
        "  return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp1VQBfMU3rl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "469c9876-f162-4d2c-ee2a-a2e044657fce"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "lst_stopwords = stopwords.words(\"english\")\n",
        "# add the 'not' words back\n",
        "remove_list = ['ain','aren',\"aren't\",'couldn',\"couldn't\",'didn',\"didn't\",'doesn',\"doesn't\",'hadn',\"hadn't\",'hasn',\"hasn't\",'haven',\"haven't\",\n",
        "               'isn',\"isn't\",'ma','mightn',\"mightn't\",'mustn',\"mustn't\",'needn',\"needn't\",'shan',\"shan't\",'shouldn',\"shouldn't\",'wasn',\"wasn't\",\n",
        "               'weren',\"weren't\",'won',\"won't\",'wouldn',\"wouldn't\",'against','no','nor','not','don', \"don't\",'t','s','y','o','d','m']\n",
        "\n",
        "for delItem in remove_list:\n",
        "  lst_stopwords.remove(delItem)\n",
        "lst_stopwords"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'myself',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'll',\n",
              " 're',\n",
              " 've']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8xKAJOIWRb0",
        "outputId": "302103fe-2969-4051-a8c4-a8887051ce98"
      },
      "source": [
        "lst_stopwords[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "erT1RnpbZvpP",
        "outputId": "f2abfe49-1b18-4988-c720-61bf76ed7b35"
      },
      "source": [
        "df_target[\"text_clean\"] = df_target[\"Text\"].apply(lambda x:\n",
        "utils_preprocess_text(x,flg_lemm=True,\n",
        "lst_stopwords=lst_stopwords))\n",
        "df_target.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Score</th>\n",
              "      <th>Text</th>\n",
              "      <th>text_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>465223</th>\n",
              "      <td>465224</td>\n",
              "      <td>1</td>\n",
              "      <td>I love Amazon...but this product showed up wit...</td>\n",
              "      <td>love amazonbut product showed le 2 month datin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4698</th>\n",
              "      <td>4699</td>\n",
              "      <td>3</td>\n",
              "      <td>The set is bigger than I thought it would be. ...</td>\n",
              "      <td>set bigger thought would would take big cake s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143999</th>\n",
              "      <td>144000</td>\n",
              "      <td>4</td>\n",
              "      <td>Clorets has been my favorite gum since the 80'...</td>\n",
              "      <td>clorets favorite gum since 80 stole piece mom ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298975</th>\n",
              "      <td>298976</td>\n",
              "      <td>4</td>\n",
              "      <td>Slightly richer chocolate taste over the milk ...</td>\n",
              "      <td>slightly richer chocolate taste milk chocolate...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361440</th>\n",
              "      <td>361441</td>\n",
              "      <td>1</td>\n",
              "      <td>As a connoissuer of a wide variety of fine loo...</td>\n",
              "      <td>connoissuer wide variety fine loose tea sold t...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Id  ...                                         text_clean\n",
              "465223  465224  ...  love amazonbut product showed le 2 month datin...\n",
              "4698      4699  ...  set bigger thought would would take big cake s...\n",
              "143999  144000  ...  clorets favorite gum since 80 stole piece mom ...\n",
              "298975  298976  ...  slightly richer chocolate taste milk chocolate...\n",
              "361440  361441  ...  connoissuer wide variety fine loose tea sold t...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gO0Hb746FFpo"
      },
      "source": [
        "### Divide into 70% training dataset and 30% testing dataset. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p-2YDKdFQyd"
      },
      "source": [
        "data_train,data_test = model_selection.train_test_split(df_target,test_size = 0.3)\n",
        "\n",
        "X_train = data_train['text_clean']\n",
        "X_test = data_test['text_clean']\n",
        "Y_train = data_train['Score']\n",
        "Y_test = data_test['Score']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eii7RxAZXx1Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a933f5d5-e427-4b15-f08d-82e540952721"
      },
      "source": [
        "#Implement one hot encoding on the label\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "y = np.asarray(Y_train)\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "y_train_onehot = y.reshape(len(y), 1)\n",
        "y_train_onehot = onehot_encoder.fit_transform(y_train_onehot)\n",
        "\n",
        "y = np.asarray(Y_test)\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "y_test_onehot = y.reshape(len(y), 1)\n",
        "y_test_onehot = onehot_encoder.fit_transform(y_test_onehot)\n",
        "y_test_onehot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 1.],\n",
              "       [1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QR1kkbVBcPlR"
      },
      "source": [
        "## 2.2 Tf-**Idf**\n",
        "Since directly using the bag of words will make the feature matrix quite large, we plan to use term frequencyâ€“inverse document frequency (Tf-Idf) to reduce the dimensionality problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4s1QQVHdeqT"
      },
      "source": [
        "### Bag of words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fi0jymMucPCU"
      },
      "source": [
        "# if we directly extract the features of text_clean \n",
        "# Set the maximum number of features to be 20000\n",
        "vectorizer = feature_extraction.text.CountVectorizer(max_features=20000, ngram_range=(1,2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EVr6p7UcPDh",
        "outputId": "6c53b2c3-41b0-4bd1-969c-6edd30158d2f"
      },
      "source": [
        "corpus = X_train\n",
        "vectorizer.fit(corpus)\n",
        "X_train_trans = vectorizer.transform(X_train)\n",
        "# dic_vocabulary = vectorizer.vocabulary_\n",
        "X_train_trans.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(91073, 20000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwtMV9NGWemp"
      },
      "source": [
        "### Using chi-square to remove irelevant features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "of2Ty1d9TDlK",
        "outputId": "23c7fc28-c5b7-49c7-fb5d-7317a0cf1790"
      },
      "source": [
        "'''\n",
        "Remove the features whose p-value is less than 0.96\n",
        "'''\n",
        "from sklearn import feature_selection\n",
        "X_try = X_train_trans\n",
        "y_try = Y_train\n",
        "X_names = vectorizer.get_feature_names()\n",
        "p_value_limit = 0.96\n",
        "df_features = pd.DataFrame()\n",
        "for cat in np.unique(y_try):\n",
        "    chi2, p = feature_selection.chi2(X_try, y_try==cat)\n",
        "    df_features = df_features.append(pd.DataFrame(\n",
        "                   {\"feature\":X_names, \"score\":1-p, \"y\":cat}))\n",
        "    df_features = df_features.sort_values([\"y\",\"score\"], \n",
        "                    ascending=[True,False])\n",
        "    df_features = df_features[df_features[\"score\"]>p_value_limit]\n",
        "X_names = df_features[\"feature\"].unique().tolist()\n",
        "len(X_names)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16381"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4R-3DM4XDxQ"
      },
      "source": [
        "We notice that the number of features decreased from 20,000 to 16381"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdVL3_LOXm6d"
      },
      "source": [
        "### Implement Tf-Idf "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dGCmrPeVaru"
      },
      "source": [
        "\n",
        "# The feature was represent by the frequency how commonly they occur in some datasets \n",
        "vectorizer = feature_extraction.text.TfidfVectorizer(vocabulary=X_names)\n",
        "vectorizer.fit(corpus)\n",
        "X_train = vectorizer.transform(X_train)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qycZD2opqab6",
        "outputId": "c581aa12-b6c3-4405-9075-19c8e6f8f440"
      },
      "source": [
        "print(X_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 15693)\t0.2686922907443722\n",
            "  (0, 13915)\t0.10869201855200344\n",
            "  (0, 12738)\t0.19074537311420195\n",
            "  (0, 10921)\t0.2260722871172582\n",
            "  (0, 9873)\t0.12813784524308855\n",
            "  (0, 8901)\t0.1659179826695976\n",
            "  (0, 5843)\t0.1871641747522728\n",
            "  (0, 5490)\t0.15780456659310566\n",
            "  (0, 2465)\t0.3120358572222012\n",
            "  (0, 2104)\t0.09230203966451628\n",
            "  (0, 2056)\t0.17043143655910237\n",
            "  (0, 1755)\t0.11473823276103462\n",
            "  (0, 1625)\t0.13814753511180636\n",
            "  (0, 1578)\t0.15891577394477577\n",
            "  (0, 1556)\t0.13380968558759493\n",
            "  (0, 1128)\t0.092535829256702\n",
            "  (0, 1058)\t0.11839575739980847\n",
            "  (0, 1043)\t0.195685306765782\n",
            "  (0, 1008)\t0.19577765633016633\n",
            "  (0, 988)\t0.13955765364799735\n",
            "  (0, 893)\t0.24523327377870635\n",
            "  (0, 844)\t0.2419430743873203\n",
            "  (0, 782)\t0.0879827914686963\n",
            "  (0, 779)\t0.23821053055952363\n",
            "  (0, 752)\t0.18211752179114934\n",
            "  (0, 706)\t0.0638315226420767\n",
            "  (0, 526)\t0.15428986471174344\n",
            "  (0, 473)\t0.10146137618998233\n",
            "  (0, 179)\t0.16384732026185886\n",
            "  (0, 134)\t0.11012241511637864\n",
            "  (0, 110)\t0.12254242814149514\n",
            "  (0, 33)\t0.2365601420427902\n",
            "  (0, 21)\t0.17647873333417122\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpB9cHgDzT9y"
      },
      "source": [
        "## 2.3 Bayesâ€™ Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VODhMfwgjX3i"
      },
      "source": [
        "classifier = naive_bayes.MultinomialNB()\n",
        "## pipeline\n",
        "model = pipeline.Pipeline([(\"vectorizer\", vectorizer),  \n",
        "              (\"classifier\", classifier)])\n",
        "## train classifier\n",
        "model[\"classifier\"].fit(X_train, Y_train)\n",
        "## test\n",
        "Y_predicted = model.predict(X_test)\n",
        "predicted_prob = model.predict_proba(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqQzPjZKZJyD"
      },
      "source": [
        "> Display the prediction results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UO03oDCYZL4f",
        "outputId": "e1b6663f-908f-4b73-995a-b5f9b23de952"
      },
      "source": [
        "from sklearn import metrics \n",
        "classes = np.unique(Y_test)\n",
        "y_test_values = pd.get_dummies(Y_test, drop_first=False).values\n",
        "# Accuracy, Auc\n",
        "accuracy = metrics.accuracy_score(Y_test, Y_predicted)\n",
        "auc = metrics.roc_auc_score(Y_test, predicted_prob,multi_class=\"ovr\")\n",
        "print(\"Accuracy:\", round(accuracy,2))\n",
        "print(\"Auc:\", round(auc,2))\n",
        "print(\"Detail:\")\n",
        "print(metrics.classification_report(Y_test, Y_predicted))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 0.52\n",
            "Auc: 0.81\n",
            "Detail:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.57      0.69      0.62      8701\n",
            "           2       0.43      0.52      0.47      7915\n",
            "           3       0.52      0.13      0.21      6426\n",
            "           4       0.45      0.35      0.39      7249\n",
            "           5       0.57      0.76      0.65      8741\n",
            "\n",
            "    accuracy                           0.52     39032\n",
            "   macro avg       0.51      0.49      0.47     39032\n",
            "weighted avg       0.51      0.52      0.49     39032\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLl3lhywWej2"
      },
      "source": [
        "The previous scores are not high enough, draw out the confusion matrix to find out the gap.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "l1f049jtjr0s",
        "outputId": "8ee4b10b-687e-4982-bc29-d1d59ef76cd8"
      },
      "source": [
        "# Plot confusion matrix\n",
        "confusion_matrix = metrics.confusion_matrix(Y_test, Y_predicted)\n",
        "fig, ax = plt.subplots()\n",
        "sns.heatmap(confusion_matrix, annot=True, fmt='d', ax=ax, cmap=plt.cm.Reds)\n",
        "ax.set(xlabel=\"Prediction\", ylabel=\"True\", xticklabels=classes, \n",
        "       yticklabels=classes, title=\"Confusion matrix\")\n",
        "plt.yticks(rotation=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.5, 1.5, 2.5, 3.5, 4.5]), <a list of 5 Text major ticklabel objects>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_tYFJoaW9k3"
      },
      "source": [
        "> Here we found that it was more difficult to distinguish between adjacent evaluations.\n",
        "\n",
        "> Probably because there is no clear boundary between adjacent comment scores (such as 4 and 5).Also we may consider to use word embedding method to decrease the number of features. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dZsqlWydj53"
      },
      "source": [
        "## 2.4 Word Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HYqmoWicfBR"
      },
      "source": [
        "corpus = df_target[\"text_clean\"]\n",
        "## create list of lists of unigrams\n",
        "save_corpus = []\n",
        "for text in corpus:\n",
        "  list_words = text.split()\n",
        "  save_corpus.append(list_words)              "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VSoLuuK9Ztmk"
      },
      "source": [
        "nlp = gensim.models.word2vec.Word2Vec(save_corpus,size = 200, sg=1, iter=10)\n",
        "word = 'like'\n",
        "nlp[word]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4WKxncY4GXmj"
      },
      "source": [
        "X_train = data_train['text_clean']\n",
        "X_test = data_test['text_clean']\n",
        "Y_train = data_train['Score']\n",
        "Y_test = data_test['Score']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wMX-1fm0S3R"
      },
      "source": [
        "# Create training corpus\n",
        "X_train_corpus = []\n",
        "for text in X_train:\n",
        "  list_words = text.split()\n",
        "  X_train_corpus.append(list_words) \n",
        "X_test_corpus = []\n",
        "for text in X_test:\n",
        "  list_words = text.split()\n",
        "  X_test_corpus.append(list_words) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDc-rNvDwhn3"
      },
      "source": [
        "# Select the word for X_train corpus\n",
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
        "num_words=None,\n",
        "filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "lower=True, split=' ', oov_token=None\n",
        ")\n",
        "tokenizer.fit_on_texts(X_train_corpus)\n",
        "# create the dictionary \n",
        "dic_vocabulary = tokenizer.word_index\n",
        "# convert the sentence into the list \n",
        "X_train_list_text= tokenizer.texts_to_sequences(X_train_corpus)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA0wA2cG2AEj",
        "outputId": "04a536cf-9184-44b2-ab81-f37472504173"
      },
      "source": [
        "length_save = [len(s) for s in X_train_list_text]\n",
        "max(length_save)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2010"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2MG-xmIBvy9t",
        "outputId": "3daf1bcd-4df8-4162-d9f6-dc75bd78f313"
      },
      "source": [
        "# padding the list with maximum length of max(length_save)\n",
        "X_train_index = kprocessing.sequence.pad_sequences(X_train_list_text, \n",
        "                    maxlen=max(length_save), padding=\"post\", truncating=\"post\")\n",
        "X_train_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 4680,   861,     6, ...,     0,     0,     0],\n",
              "       [   19,    17,    62, ...,     0,     0,     0],\n",
              "       [  322,     1,   647, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [ 2339,     5,    43, ...,     0,     0,     0],\n",
              "       [  891,   401, 16229, ...,     0,     0,     0],\n",
              "       [   16,     8,   864, ...,     0,     0,     0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iiAGJmjRAAsu",
        "outputId": "033184a7-915e-47e2-f6e2-ae562aed7d6b"
      },
      "source": [
        "# Select the word for X_test corpus\n",
        "tokenizer2 = tf.keras.preprocessing.text.Tokenizer(\n",
        "num_words=None,\n",
        "filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
        "lower=True, split=' ', oov_token=None\n",
        ")\n",
        "tokenizer2.fit_on_texts(X_test_corpus)\n",
        "# convert the sentence into the list \n",
        "X_test_list_text= tokenizer2.texts_to_sequences(X_test_corpus)\n",
        "# padding the list with maximum length of max(length_save)\n",
        "X_test_index = kprocessing.sequence.pad_sequences(X_test_list_text, \n",
        "                    maxlen=max(length_save), padding=\"post\", truncating=\"post\")\n",
        "X_test_index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    1, 11921,   482, ...,     0,     0,     0],\n",
              "       [   18,     1,     2, ...,     0,     0,     0],\n",
              "       [   15,  1488,  1477, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [  101,   504,   769, ...,     0,     0,     0],\n",
              "       [    5, 12058,   623, ...,     0,     0,     0],\n",
              "       [  956, 54389,  5984, ...,     0,     0,     0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwHxVoDSzdSp",
        "outputId": "3004388f-b149-468f-e8ab-375297f7f837"
      },
      "source": [
        "#Save the embeddings matrix\n",
        "embeddings = np.zeros((len(dic_vocabulary)+1, 200))\n",
        "for word,idx in dic_vocabulary.items():\n",
        "  try:\n",
        "    embeddings[idx] =  nlp[word]\n",
        "  except:\n",
        "    pass\n",
        "print(len(embeddings))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "85244\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcH7CyX8hE6F"
      },
      "source": [
        "## 2.5 Neural network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a-IGme4BSPx"
      },
      "source": [
        "> Input: the original sentence with the word index (m,n)\n",
        "\n",
        "m: the number of comments\n",
        "n: the length of each comment sentence after padding\n",
        "\n",
        ">  Embedding layer output: (nxp)\n",
        "n: the length of each comment sentence after padding\n",
        "p: the embedding matrix for each word index\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yD2nQOLopA29",
        "outputId": "2e2b8247-636f-4888-be77-e8cb162433a0"
      },
      "source": [
        "embeddings.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(85244, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEsah_qxqyMD"
      },
      "source": [
        "The size of the embedding matrix is too large to excute...\n",
        "\n",
        "Maybe it can be solved in the future......."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZXPiq07yu9a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "018a7b2d-d027-4c6c-f503-983fe0680549"
      },
      "source": [
        "# len_comment_index = max(length_save)\n",
        "# # input layer\n",
        "# x_in = layers.Input(shape=(len_comment_index,))\n",
        "# # embedding layer \n",
        "# x = layers.Embedding(input_dim=embeddings.shape[0],  \n",
        "#             output_dim=embeddings.shape[1], \n",
        "            \n",
        "#             trainable=False)(x_in)\n",
        "\n",
        "# # 4 layers of bidirectional lstm\n",
        "# x = layers.Bidirectional(layers.LSTM(units=len_comment_index, dropout=0.2, \n",
        "#                          return_sequences=True))(x)\n",
        "# x = layers.Bidirectional(layers.LSTM(units=len_comment_index, dropout=0.2,\n",
        "#                          return_sequences=True))(x)\n",
        "\n",
        "# x = layers.Bidirectional(layers.LSTM(units=60, dropout=0.2,\n",
        "#                          return_sequences=True))(x)\n",
        "\n",
        "# x = layers.Bidirectional(layers.LSTM(units=30, dropout=0.2))(x)\n",
        "\n",
        "\n",
        "# ## final dense layers\n",
        "# y_out = layers.Dense(20,activation='relu')(x)\n",
        "# y_out = layers.Dense(5,activation='softmax')(y_out)\n",
        "\n",
        "# ## compile\n",
        "# model = models.Model(x_in, y_out)\n",
        "# model.compile(loss='categorical_crossentropy',\n",
        "#        optimizer='adagrad', metrics=['accuracy'])\n",
        "\n",
        "# model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 2010)]            0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 2010, 200)         17048800  \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 2010, 4020)        35552880  \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 2010, 4020)        96978480  \n",
            "_________________________________________________________________\n",
            "bidirectional_2 (Bidirection (None, 2010, 120)         1958880   \n",
            "_________________________________________________________________\n",
            "bidirectional_3 (Bidirection (None, 60)                36240     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 20)                1220      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 5)                 105       \n",
            "=================================================================\n",
            "Total params: 151,576,605\n",
            "Trainable params: 134,527,805\n",
            "Non-trainable params: 17,048,800\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbMYvsy0thZe"
      },
      "source": [
        "Instead, using the embedding layer provided by the keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVRrddXDjE9o",
        "outputId": "d9385cb0-f914-43e9-b91d-387213f5b9fd"
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "# Keras tokenizer\n",
        "t = Tokenizer()\n",
        "t.fit_on_texts(save_corpus)\n",
        "# encode text to integer array\n",
        "encoded_docs = t.texts_to_sequences(save_corpus) \n",
        "# get number of vocabulary in the dict\n",
        "vocab_num = len(t.word_counts)\n",
        "# find the length of the longest review\n",
        "max_length = max([len(p) for p in encoded_docs])\n",
        "print(\"number of vocabulary in the dict: %d\" % vocab_num)\n",
        "print(\"longest review length: %d\" % max_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of vocabulary in the dict: 103338\n",
            "longest review length: 2010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jP8-PO0_jFCJ",
        "outputId": "6849d1fb-415b-45ab-d548-be0515ff9574"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "pad_comments = pad_sequences(encoded_docs, maxlen=max_length, padding='post')\n",
        "pad_comments.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(130105, 2010)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H37yMwnrjJIZ"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "y = np.asarray(df_target['Score'])\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "y_onehot = y.reshape(len(y), 1)\n",
        "y_onehot = onehot_encoder.fit_transform(y_onehot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIJhKvbBjKjM"
      },
      "source": [
        "X_train, X_test, y_train, y_test = model_selection.train_test_split(pad_comments,y_onehot, test_size=0.2, random_state = 42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ymVxf1-jMFV",
        "outputId": "81bd55b8-c181-4a05-d98a-5dba3be1b743"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Embedding\n",
        "# define the model\n",
        "model = Sequential()\n",
        "model.add(Embedding(vocab_num+1, 10, input_length=max_length))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(5, activation='softmax'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adagrad', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# summarize the model\n",
        "print(model.summary())\n",
        "# fit the model\n",
        "history = model.fit(X_train, y_train, epochs=150, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_2 (Embedding)      (None, 2010, 10)          1033390   \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 20100)             0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 64)                1286464   \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 128)               8320      \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 5)                 325       \n",
            "=================================================================\n",
            "Total params: 2,336,755\n",
            "Trainable params: 2,336,755\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "2603/2603 [==============================] - 17s 6ms/step - loss: 1.6040 - accuracy: 0.2233 - val_loss: 1.6022 - val_accuracy: 0.2361\n",
            "Epoch 2/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.6014 - accuracy: 0.2368 - val_loss: 1.6010 - val_accuracy: 0.2430\n",
            "Epoch 3/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.6002 - accuracy: 0.2414 - val_loss: 1.6004 - val_accuracy: 0.2443\n",
            "Epoch 4/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.5986 - accuracy: 0.2450 - val_loss: 1.5985 - val_accuracy: 0.2462\n",
            "Epoch 5/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.5964 - accuracy: 0.2465 - val_loss: 1.5973 - val_accuracy: 0.2412\n",
            "Epoch 6/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 1.5961 - accuracy: 0.2466 - val_loss: 1.5968 - val_accuracy: 0.2472\n",
            "Epoch 7/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.5948 - accuracy: 0.2448 - val_loss: 1.5950 - val_accuracy: 0.2468\n",
            "Epoch 8/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.5926 - accuracy: 0.2527 - val_loss: 1.5936 - val_accuracy: 0.2503\n",
            "Epoch 9/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.5917 - accuracy: 0.2543 - val_loss: 1.5915 - val_accuracy: 0.2544\n",
            "Epoch 10/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.5881 - accuracy: 0.2579 - val_loss: 1.5893 - val_accuracy: 0.2611\n",
            "Epoch 11/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.5866 - accuracy: 0.2605 - val_loss: 1.5850 - val_accuracy: 0.2648\n",
            "Epoch 12/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 1.5812 - accuracy: 0.2710 - val_loss: 1.5792 - val_accuracy: 0.2743\n",
            "Epoch 13/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.5755 - accuracy: 0.2760 - val_loss: 1.5700 - val_accuracy: 0.2888\n",
            "Epoch 14/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.5624 - accuracy: 0.2949 - val_loss: 1.5540 - val_accuracy: 0.3064\n",
            "Epoch 15/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.5450 - accuracy: 0.3073 - val_loss: 1.5310 - val_accuracy: 0.3149\n",
            "Epoch 16/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.5177 - accuracy: 0.3282 - val_loss: 1.5123 - val_accuracy: 0.3219\n",
            "Epoch 17/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.4858 - accuracy: 0.3430 - val_loss: 1.4737 - val_accuracy: 0.3440\n",
            "Epoch 18/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.4585 - accuracy: 0.3540 - val_loss: 1.4463 - val_accuracy: 0.3564\n",
            "Epoch 19/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.4279 - accuracy: 0.3634 - val_loss: 1.4235 - val_accuracy: 0.3668\n",
            "Epoch 20/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.4010 - accuracy: 0.3754 - val_loss: 1.3972 - val_accuracy: 0.3770\n",
            "Epoch 21/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.3798 - accuracy: 0.3828 - val_loss: 1.3824 - val_accuracy: 0.3801\n",
            "Epoch 22/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.3632 - accuracy: 0.3888 - val_loss: 1.3679 - val_accuracy: 0.3889\n",
            "Epoch 23/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.3454 - accuracy: 0.3967 - val_loss: 1.3546 - val_accuracy: 0.3916\n",
            "Epoch 24/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.3298 - accuracy: 0.4016 - val_loss: 1.3397 - val_accuracy: 0.4006\n",
            "Epoch 25/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.3180 - accuracy: 0.4064 - val_loss: 1.3297 - val_accuracy: 0.4033\n",
            "Epoch 26/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.3061 - accuracy: 0.4146 - val_loss: 1.3179 - val_accuracy: 0.4089\n",
            "Epoch 27/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.2981 - accuracy: 0.4148 - val_loss: 1.3223 - val_accuracy: 0.4105\n",
            "Epoch 28/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.2866 - accuracy: 0.4215 - val_loss: 1.3147 - val_accuracy: 0.4104\n",
            "Epoch 29/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.2824 - accuracy: 0.4204 - val_loss: 1.2999 - val_accuracy: 0.4176\n",
            "Epoch 30/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.2717 - accuracy: 0.4280 - val_loss: 1.2902 - val_accuracy: 0.4211\n",
            "Epoch 31/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.2615 - accuracy: 0.4322 - val_loss: 1.2856 - val_accuracy: 0.4221\n",
            "Epoch 32/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.2573 - accuracy: 0.4346 - val_loss: 1.2765 - val_accuracy: 0.4279\n",
            "Epoch 33/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.2463 - accuracy: 0.4409 - val_loss: 1.2720 - val_accuracy: 0.4290\n",
            "Epoch 34/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.2439 - accuracy: 0.4380 - val_loss: 1.2664 - val_accuracy: 0.4326\n",
            "Epoch 35/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.2391 - accuracy: 0.4391 - val_loss: 1.2802 - val_accuracy: 0.4272\n",
            "Epoch 36/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.2300 - accuracy: 0.4457 - val_loss: 1.2824 - val_accuracy: 0.4249\n",
            "Epoch 37/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.2256 - accuracy: 0.4494 - val_loss: 1.2534 - val_accuracy: 0.4382\n",
            "Epoch 38/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.2239 - accuracy: 0.4484 - val_loss: 1.2555 - val_accuracy: 0.4384\n",
            "Epoch 39/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.2180 - accuracy: 0.4506 - val_loss: 1.2668 - val_accuracy: 0.4342\n",
            "Epoch 40/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.2143 - accuracy: 0.4534 - val_loss: 1.2428 - val_accuracy: 0.4424\n",
            "Epoch 41/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.2058 - accuracy: 0.4568 - val_loss: 1.2399 - val_accuracy: 0.4442\n",
            "Epoch 42/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.1934 - accuracy: 0.4672 - val_loss: 1.2365 - val_accuracy: 0.4452\n",
            "Epoch 43/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.1983 - accuracy: 0.4648 - val_loss: 1.2534 - val_accuracy: 0.4413\n",
            "Epoch 44/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.1911 - accuracy: 0.4644 - val_loss: 1.2363 - val_accuracy: 0.4476\n",
            "Epoch 45/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.1859 - accuracy: 0.4705 - val_loss: 1.2249 - val_accuracy: 0.4529\n",
            "Epoch 46/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.1814 - accuracy: 0.4714 - val_loss: 1.2221 - val_accuracy: 0.4531\n",
            "Epoch 47/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.1768 - accuracy: 0.4761 - val_loss: 1.2402 - val_accuracy: 0.4485\n",
            "Epoch 48/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.1791 - accuracy: 0.4752 - val_loss: 1.2152 - val_accuracy: 0.4566\n",
            "Epoch 49/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.1692 - accuracy: 0.4787 - val_loss: 1.2125 - val_accuracy: 0.4589\n",
            "Epoch 50/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.1650 - accuracy: 0.4823 - val_loss: 1.2137 - val_accuracy: 0.4627\n",
            "Epoch 51/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.1611 - accuracy: 0.4812 - val_loss: 1.2155 - val_accuracy: 0.4602\n",
            "Epoch 52/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.1591 - accuracy: 0.4862 - val_loss: 1.2029 - val_accuracy: 0.4673\n",
            "Epoch 53/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.1508 - accuracy: 0.4900 - val_loss: 1.2010 - val_accuracy: 0.4682\n",
            "Epoch 54/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.1399 - accuracy: 0.4948 - val_loss: 1.1988 - val_accuracy: 0.4676\n",
            "Epoch 55/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.1417 - accuracy: 0.4975 - val_loss: 1.1946 - val_accuracy: 0.4701\n",
            "Epoch 56/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.1354 - accuracy: 0.5002 - val_loss: 1.1953 - val_accuracy: 0.4694\n",
            "Epoch 57/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.1346 - accuracy: 0.5003 - val_loss: 1.1937 - val_accuracy: 0.4712\n",
            "Epoch 58/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.1319 - accuracy: 0.5006 - val_loss: 1.1874 - val_accuracy: 0.4764\n",
            "Epoch 59/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 1.1293 - accuracy: 0.5046 - val_loss: 1.1842 - val_accuracy: 0.4795\n",
            "Epoch 60/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 1.1186 - accuracy: 0.5086 - val_loss: 1.1897 - val_accuracy: 0.4804\n",
            "Epoch 61/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 1.1163 - accuracy: 0.5125 - val_loss: 1.1780 - val_accuracy: 0.4852\n",
            "Epoch 62/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.1110 - accuracy: 0.5152 - val_loss: 1.1790 - val_accuracy: 0.4835\n",
            "Epoch 63/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 1.1107 - accuracy: 0.5145 - val_loss: 1.1869 - val_accuracy: 0.4829\n",
            "Epoch 64/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 1.1055 - accuracy: 0.5164 - val_loss: 1.1720 - val_accuracy: 0.4887\n",
            "Epoch 65/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 1.1008 - accuracy: 0.5212 - val_loss: 1.1705 - val_accuracy: 0.4909\n",
            "Epoch 66/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 1.0954 - accuracy: 0.5184 - val_loss: 1.1691 - val_accuracy: 0.4909\n",
            "Epoch 67/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 1.0941 - accuracy: 0.5258 - val_loss: 1.1754 - val_accuracy: 0.4892\n",
            "Epoch 68/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 1.0908 - accuracy: 0.5241 - val_loss: 1.1646 - val_accuracy: 0.4945\n",
            "Epoch 69/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0894 - accuracy: 0.5247 - val_loss: 1.1650 - val_accuracy: 0.4957\n",
            "Epoch 70/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 1.0843 - accuracy: 0.5289 - val_loss: 1.1636 - val_accuracy: 0.4961\n",
            "Epoch 71/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0791 - accuracy: 0.5299 - val_loss: 1.1578 - val_accuracy: 0.4983\n",
            "Epoch 72/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0761 - accuracy: 0.5327 - val_loss: 1.1561 - val_accuracy: 0.5005\n",
            "Epoch 73/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0751 - accuracy: 0.5325 - val_loss: 1.1600 - val_accuracy: 0.4945\n",
            "Epoch 74/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0700 - accuracy: 0.5355 - val_loss: 1.1544 - val_accuracy: 0.5025\n",
            "Epoch 75/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0673 - accuracy: 0.5364 - val_loss: 1.1549 - val_accuracy: 0.5021\n",
            "Epoch 76/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0576 - accuracy: 0.5413 - val_loss: 1.1541 - val_accuracy: 0.5006\n",
            "Epoch 77/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0621 - accuracy: 0.5380 - val_loss: 1.1502 - val_accuracy: 0.5057\n",
            "Epoch 78/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0593 - accuracy: 0.5423 - val_loss: 1.1482 - val_accuracy: 0.5070\n",
            "Epoch 79/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0572 - accuracy: 0.5440 - val_loss: 1.1636 - val_accuracy: 0.4969\n",
            "Epoch 80/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0529 - accuracy: 0.5463 - val_loss: 1.1461 - val_accuracy: 0.5065\n",
            "Epoch 81/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0518 - accuracy: 0.5446 - val_loss: 1.1488 - val_accuracy: 0.5088\n",
            "Epoch 82/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0461 - accuracy: 0.5477 - val_loss: 1.1485 - val_accuracy: 0.5096\n",
            "Epoch 83/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0443 - accuracy: 0.5481 - val_loss: 1.1466 - val_accuracy: 0.5074\n",
            "Epoch 84/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0389 - accuracy: 0.5516 - val_loss: 1.1433 - val_accuracy: 0.5118\n",
            "Epoch 85/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 1.0424 - accuracy: 0.5510 - val_loss: 1.1429 - val_accuracy: 0.5125\n",
            "Epoch 86/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0393 - accuracy: 0.5506 - val_loss: 1.1408 - val_accuracy: 0.5128\n",
            "Epoch 87/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0334 - accuracy: 0.5536 - val_loss: 1.1405 - val_accuracy: 0.5149\n",
            "Epoch 88/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0309 - accuracy: 0.5575 - val_loss: 1.1373 - val_accuracy: 0.5154\n",
            "Epoch 89/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0319 - accuracy: 0.5548 - val_loss: 1.1366 - val_accuracy: 0.5160\n",
            "Epoch 90/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0255 - accuracy: 0.5610 - val_loss: 1.1391 - val_accuracy: 0.5160\n",
            "Epoch 91/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0186 - accuracy: 0.5593 - val_loss: 1.1368 - val_accuracy: 0.5158\n",
            "Epoch 92/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0224 - accuracy: 0.5611 - val_loss: 1.1362 - val_accuracy: 0.5161\n",
            "Epoch 93/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0182 - accuracy: 0.5651 - val_loss: 1.1354 - val_accuracy: 0.5172\n",
            "Epoch 94/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0144 - accuracy: 0.5651 - val_loss: 1.1346 - val_accuracy: 0.5182\n",
            "Epoch 95/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0171 - accuracy: 0.5646 - val_loss: 1.1372 - val_accuracy: 0.5157\n",
            "Epoch 96/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0117 - accuracy: 0.5667 - val_loss: 1.1312 - val_accuracy: 0.5201\n",
            "Epoch 97/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0071 - accuracy: 0.5690 - val_loss: 1.1507 - val_accuracy: 0.5172\n",
            "Epoch 98/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0036 - accuracy: 0.5709 - val_loss: 1.1472 - val_accuracy: 0.5141\n",
            "Epoch 99/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0028 - accuracy: 0.5713 - val_loss: 1.1431 - val_accuracy: 0.5187\n",
            "Epoch 100/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 1.0035 - accuracy: 0.5665 - val_loss: 1.1294 - val_accuracy: 0.5212\n",
            "Epoch 101/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 0.9956 - accuracy: 0.5744 - val_loss: 1.1291 - val_accuracy: 0.5228\n",
            "Epoch 102/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 0.9956 - accuracy: 0.5741 - val_loss: 1.1339 - val_accuracy: 0.5232\n",
            "Epoch 103/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 0.9898 - accuracy: 0.5786 - val_loss: 1.1412 - val_accuracy: 0.5214\n",
            "Epoch 104/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 0.9889 - accuracy: 0.5782 - val_loss: 1.1324 - val_accuracy: 0.5213\n",
            "Epoch 105/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 0.9880 - accuracy: 0.5790 - val_loss: 1.1295 - val_accuracy: 0.5245\n",
            "Epoch 106/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 0.9841 - accuracy: 0.5805 - val_loss: 1.1359 - val_accuracy: 0.5260\n",
            "Epoch 107/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 0.9867 - accuracy: 0.5802 - val_loss: 1.1274 - val_accuracy: 0.5267\n",
            "Epoch 108/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9790 - accuracy: 0.5841 - val_loss: 1.1294 - val_accuracy: 0.5243\n",
            "Epoch 109/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9756 - accuracy: 0.5870 - val_loss: 1.1262 - val_accuracy: 0.5276\n",
            "Epoch 110/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 0.9757 - accuracy: 0.5850 - val_loss: 1.1299 - val_accuracy: 0.5294\n",
            "Epoch 111/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 0.9707 - accuracy: 0.5881 - val_loss: 1.1268 - val_accuracy: 0.5284\n",
            "Epoch 112/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9733 - accuracy: 0.5838 - val_loss: 1.1286 - val_accuracy: 0.5273\n",
            "Epoch 113/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9720 - accuracy: 0.5874 - val_loss: 1.1256 - val_accuracy: 0.5297\n",
            "Epoch 114/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9664 - accuracy: 0.5918 - val_loss: 1.1286 - val_accuracy: 0.5309\n",
            "Epoch 115/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 0.9626 - accuracy: 0.5937 - val_loss: 1.1258 - val_accuracy: 0.5302\n",
            "Epoch 116/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9657 - accuracy: 0.5924 - val_loss: 1.1328 - val_accuracy: 0.5273\n",
            "Epoch 117/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9603 - accuracy: 0.5937 - val_loss: 1.1259 - val_accuracy: 0.5298\n",
            "Epoch 118/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9592 - accuracy: 0.5950 - val_loss: 1.1431 - val_accuracy: 0.5238\n",
            "Epoch 119/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 0.9547 - accuracy: 0.5976 - val_loss: 1.1398 - val_accuracy: 0.5237\n",
            "Epoch 120/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9520 - accuracy: 0.5980 - val_loss: 1.1297 - val_accuracy: 0.5317\n",
            "Epoch 121/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9525 - accuracy: 0.5983 - val_loss: 1.1249 - val_accuracy: 0.5319\n",
            "Epoch 122/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9535 - accuracy: 0.5970 - val_loss: 1.1270 - val_accuracy: 0.5339\n",
            "Epoch 123/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9504 - accuracy: 0.6006 - val_loss: 1.1249 - val_accuracy: 0.5334\n",
            "Epoch 124/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9474 - accuracy: 0.5997 - val_loss: 1.1243 - val_accuracy: 0.5334\n",
            "Epoch 125/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 0.9438 - accuracy: 0.6038 - val_loss: 1.1303 - val_accuracy: 0.5339\n",
            "Epoch 126/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9463 - accuracy: 0.5991 - val_loss: 1.1315 - val_accuracy: 0.5314\n",
            "Epoch 127/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 0.9420 - accuracy: 0.6049 - val_loss: 1.1296 - val_accuracy: 0.5331\n",
            "Epoch 128/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9412 - accuracy: 0.6060 - val_loss: 1.1245 - val_accuracy: 0.5359\n",
            "Epoch 129/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9382 - accuracy: 0.6069 - val_loss: 1.1244 - val_accuracy: 0.5349\n",
            "Epoch 130/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9342 - accuracy: 0.6085 - val_loss: 1.1297 - val_accuracy: 0.5360\n",
            "Epoch 131/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9318 - accuracy: 0.6087 - val_loss: 1.1262 - val_accuracy: 0.5365\n",
            "Epoch 132/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9335 - accuracy: 0.6107 - val_loss: 1.1270 - val_accuracy: 0.5374\n",
            "Epoch 133/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9293 - accuracy: 0.6094 - val_loss: 1.1276 - val_accuracy: 0.5376\n",
            "Epoch 134/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9254 - accuracy: 0.6130 - val_loss: 1.1310 - val_accuracy: 0.5349\n",
            "Epoch 135/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9286 - accuracy: 0.6129 - val_loss: 1.1287 - val_accuracy: 0.5379\n",
            "Epoch 136/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 0.9225 - accuracy: 0.6142 - val_loss: 1.1289 - val_accuracy: 0.5377\n",
            "Epoch 137/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9219 - accuracy: 0.6139 - val_loss: 1.1271 - val_accuracy: 0.5396\n",
            "Epoch 138/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9185 - accuracy: 0.6176 - val_loss: 1.1282 - val_accuracy: 0.5384\n",
            "Epoch 139/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9171 - accuracy: 0.6206 - val_loss: 1.1353 - val_accuracy: 0.5370\n",
            "Epoch 140/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 0.9115 - accuracy: 0.6221 - val_loss: 1.1272 - val_accuracy: 0.5408\n",
            "Epoch 141/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9148 - accuracy: 0.6180 - val_loss: 1.1334 - val_accuracy: 0.5372\n",
            "Epoch 142/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9128 - accuracy: 0.6221 - val_loss: 1.1323 - val_accuracy: 0.5398\n",
            "Epoch 143/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 0.9144 - accuracy: 0.6197 - val_loss: 1.1324 - val_accuracy: 0.5393\n",
            "Epoch 144/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9108 - accuracy: 0.6200 - val_loss: 1.1349 - val_accuracy: 0.5377\n",
            "Epoch 145/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 0.9082 - accuracy: 0.6251 - val_loss: 1.1299 - val_accuracy: 0.5410\n",
            "Epoch 146/150\n",
            "2603/2603 [==============================] - 16s 6ms/step - loss: 0.9083 - accuracy: 0.6208 - val_loss: 1.1292 - val_accuracy: 0.5428\n",
            "Epoch 147/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9004 - accuracy: 0.6295 - val_loss: 1.1312 - val_accuracy: 0.5411\n",
            "Epoch 148/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.9001 - accuracy: 0.6259 - val_loss: 1.1319 - val_accuracy: 0.5416\n",
            "Epoch 149/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.8972 - accuracy: 0.6289 - val_loss: 1.1428 - val_accuracy: 0.5367\n",
            "Epoch 150/150\n",
            "2603/2603 [==============================] - 15s 6ms/step - loss: 0.8975 - accuracy: 0.6287 - val_loss: 1.1477 - val_accuracy: 0.5353\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6qWUASUqjOgS",
        "outputId": "31170744-be66-4c4f-e7d9-4af41c061352"
      },
      "source": [
        "actual_loss, actual_acc = model.evaluate(X_train, y_train)\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(\"trainning accuracy: %f \" % actual_acc)\n",
        "print(\"testing accuracy: %f \" % test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3253/3253 [==============================] - 10s 3ms/step - loss: 0.9579 - accuracy: 0.6006\n",
            "814/814 [==============================] - 2s 3ms/step - loss: 1.1495 - accuracy: 0.5321\n",
            "trainning accuracy: 0.600649 \n",
            "testing accuracy: 0.532070 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "4Lg5m291jVYt",
        "outputId": "77bcee1a-0fce-4123-c525-c2e09ce1dd7f"
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='train')\n",
        "plt.plot(history.history['val_accuracy'], label='test')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}